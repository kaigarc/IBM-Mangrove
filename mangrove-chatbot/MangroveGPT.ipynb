{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDA5ftkhQL5n"
      },
      "source": [
        "Adding Text Data to Vector DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0TLv7K1QJ6-",
        "outputId": "56c2e435-87aa-4088-a334-a32dfbbd270a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jROOe_HtQ8_T",
        "outputId": "d4a6d7c1-0c3c-4868-ceba-da7b804c1e57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.9/215.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pinecone-client langchain openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dA27qqsRJlV"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet  langchain-pinecone langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21Q0TENuRMHG",
        "outputId": "8e5dfab0-f3c3-49b6-f8c8-b5200ee2fc97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "import os\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'OPEN AI KEY'\n",
        "os.environ[\"PINECONE_API_KEY\"] = 'PINECONE API KEY'\n",
        "os.environ[\"PINECONE_INDEX_NAME\"] = 'PINE CONE INDEX'\n",
        "\n",
        "\"\"\"\n",
        "#txt file location\n",
        "text = '/content/drive/MyDrive/IBM_Spring24/paper scraping/mangrove_policy_text.txt'\n",
        "\n",
        "# Function to split text from a file into chunks by every 6 sentences\n",
        "def split_into_chunks_from_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return split_into_chunks(text)\n",
        "\n",
        "def split_into_chunks(text):\n",
        "    text_splitter = TokenTextSplitter(chunk_size=768, chunk_overlap=20)\n",
        "    return text_splitter.split_text(text)\n",
        "\n",
        "chunks = split_into_chunks_from_file(text)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvwhLyo-RYzh"
      },
      "outputs": [],
      "source": [
        "from langchain_pinecone import Pinecone\n",
        "embeddings = OpenAIEmbeddings()\n",
        "db = Pinecone.from_existing_index(index_name=\"mangrove-index\", embedding = embeddings)\n",
        "#db.add_texts([chunk for chunk in chunks])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_VSkSvgRfO9"
      },
      "source": [
        "Setting up RAG + Runnign QnA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDcAh6r2RcBP",
        "outputId": "f9c3b7f6-e633-47f5-82f4-ecfc7189258f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MwMFcuBRlIo"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYoJvrgaRnXA"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages= True)\n",
        "chain = ConversationalRetrievalChain.from_llm(llm, retriever= retriever, memory= memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yI2W7yZ6RqMl"
      },
      "outputs": [],
      "source": [
        "link = 'https://www.mangrovealliance.org/wp-content/uploads/2023/12/GMA-Policy-Brief_V6.pdf'\n",
        "\n",
        "query_template = f\"\"\"\n",
        "                  For the following query, provide detailed informational input regarding mangroves. If possible,\n",
        "                  cite specific numbers/events/policies. If answer is not known, respond\n",
        "                  'I'm not sure, but some relevant information can be found here: {link}'.\n",
        "\n",
        "                  example:\n",
        "                  Questions: Tell me about mangrove change in Senegal.\n",
        "                  Answer: Mangroves in Senegal have undergone a notable decline since 1980, with the mangrove area in the country shrinking from 2300 km in 1990 to 1760 km in 2008. Over 30 years, the Saloum reserve of the biosphere's mangrove has lost approximately 40% of its area, amounting to about 750 km. Similarly, in Casamance, around 670 km of the ecosystem vanished during the same period. Despite these losses, recent studies indicate a potential recovery in certain areas, such as the Senegal-Gambia border of Saloum-Niumi and the Blis-Karone islands of Casamance. In these areas, women engaged in shellfish harvesting have observed changes in the mangrove forest, noting a decrease in density and a decline in the size and abundance of oysters and arches. The reasons behind the decline of mangroves in Senegal are multifaceted, including factors such as drought, the introduction of new techniques by both public and private actors, and the impact of the prolonged conflict in Casamance. During reforestation campaigns, women interviewed have voiced concerns about the degradation of mangroves and emphasized the importance of adopting sustainable management practices to address these issues.\n",
        "\n",
        "                  The query is as follows:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "ct-F400THZZm",
        "outputId": "828dc121-320f-4923-d703-5016c7cb2940"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Some important policies in Senegal for protecting mangroves include the promotion of responsible and fair harvesting practices, the establishment of local \"conventions\" by local people with the support of NGOs and international organizations, and the implementation of the \"Plant your tree\" program. Additionally, there is a Mangrove Charter and national action plans in place to promote inclusive and long-term governance of mangroves. The country also participates in the West Africa Marine and Coastal Conservation Platform (PRCM) to coordinate mangrove conservation efforts at a sub-regional level.'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_input = 'tell me about important policies in Senegal for mangroves'\n",
        "chain.run({'question': query_template + query_input})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1KibWe2NbFz"
      },
      "source": [
        "Generating Visualizations **NOT WORKING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXUzxykObdbH",
        "outputId": "70edb729-3e36-4cb9-d9d3-5acaed298250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/194.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q tabulate langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUKwW8wN7-Q"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "def create_agent(filename: str):\n",
        "    \"\"\"\n",
        "    Create an agent that can access and use a large language model (LLM).\n",
        "\n",
        "    Args:\n",
        "        filename: The path to the CSV file that contains the data.\n",
        "\n",
        "    Returns:\n",
        "        An agent that can access and use the LLM.\n",
        "    \"\"\"\n",
        "\n",
        "    # Read the CSV file into a Pandas DataFrame.\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    # Create a Pandas DataFrame agent.\n",
        "    return create_pandas_dataframe_agent(llm, df, verbose=False)\n",
        "\n",
        "def query_agent(agent, query):\n",
        "    \"\"\"\n",
        "    Query an agent and return the response as a string.\n",
        "\n",
        "    Args:\n",
        "        agent: The agent to query.\n",
        "        query: The query to ask the agent.\n",
        "\n",
        "    Returns:\n",
        "        The response from the agent as a string.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = (\n",
        "        \"\"\"\n",
        "            For the following query, if it requires drawing a table, reply as follows:\n",
        "            {\"table\": {\"columns\": [\"column1\", \"column2\", ...], \"data\": [[value1, value2, ...], [value1, value2, ...], ...]}}\n",
        "\n",
        "            If the query requires creating a bar chart, reply as follows:\n",
        "            {\"bar\": {\"columns\": [\"A\", \"B\", \"C\", ...], \"data\": [25, 24, 10, ...]}}\n",
        "\n",
        "            If the query requires creating a line chart, reply as follows:\n",
        "            {\"line\": {\"columns\": [\"A\", \"B\", \"C\", ...], \"data\": [25, 24, 10, ...]}}\n",
        "\n",
        "            There can only be two types of chart, \"bar\" and \"line\".\n",
        "\n",
        "            If it is just asking a question that requires neither, reply as follows:\n",
        "            {\"answer\": \"answer\"}\n",
        "            Example:\n",
        "            {\"answer\": \"The country with the greatest increase in mangrove area is 'Indonesia'\"}\n",
        "\n",
        "            If you do not know the answer, reply as follows:\n",
        "            {\"answer\": \"I do not know.\"}\n",
        "\n",
        "            Return all output as a string.\n",
        "\n",
        "            All strings in \"columns\" list and data list, should be in double quotes,\n",
        "\n",
        "            For example: {\"columns\": [\"country\", \"quantity\"], \"data\": [[\"India\", 1361], [\"Brazil\", 5164]]}\n",
        "\n",
        "            Lets think step by step.\n",
        "\n",
        "            Below is the query for the mangrove square footage dataset.\n",
        "            Query:\n",
        "            \"\"\"\n",
        "        + query\n",
        "    )\n",
        "\n",
        "    # Run the prompt through the agent.\n",
        "    response = agent.run(prompt)\n",
        "\n",
        "    # Convert the response to a string.\n",
        "    return response.__str__()\n",
        "\n",
        "def decode_response(response: str) -> dict:\n",
        "    \"\"\"This function converts the string response from the model to a dictionary object.\n",
        "\n",
        "    Args:\n",
        "        response (str): response from the model\n",
        "\n",
        "    Returns:\n",
        "        dict: dictionary with response data\n",
        "    \"\"\"\n",
        "    if not response:\n",
        "        raise ValueError(\"error processing response\")\n",
        "    return json.loads(response)\n",
        "\n",
        "def write_response(response_dict: dict):\n",
        "    \"\"\"\n",
        "    Write a response from agent.\n",
        "\n",
        "    Args:\n",
        "        response_dict: The response from the agent.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Check if the response is an answer.\n",
        "    if \"answer\" in response_dict:\n",
        "        print(response_dict[\"answer\"])\n",
        "\n",
        "    # Check if the response is a bar chart.\n",
        "    if \"bar\" in response_dict:\n",
        "        data = response_dict[\"bar\"]\n",
        "        df = pd.DataFrame(data)\n",
        "        df.set_index(\"columns\", inplace=True)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.bar(df.index, df.values)\n",
        "        plt.xlabel('Columns')\n",
        "        plt.ylabel('Values')\n",
        "        plt.title('Bar Chart')\n",
        "        plt.show()  # Show the bar chart inline\n",
        "\n",
        "    # Check if the response is a line chart.\n",
        "    if \"line\" in response_dict:\n",
        "        data = response_dict[\"line\"]\n",
        "        df = pd.DataFrame(data)\n",
        "        df.set_index(\"columns\", inplace=True)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        for column in df.columns:\n",
        "            plt.plot(df.index, df[column], label=column)\n",
        "        plt.xlabel('Columns')\n",
        "        plt.ylabel('Values')\n",
        "        plt.title('Line Chart')\n",
        "        plt.legend()\n",
        "        plt.show()  # Show the line chart inline\n",
        "\n",
        "    # Check if the response is a table.\n",
        "    if \"table\" in response_dict:\n",
        "        data = response_dict[\"table\"]\n",
        "        df = pd.DataFrame(data)\n",
        "        print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efweL9EGQRjI"
      },
      "outputs": [],
      "source": [
        "#running the agent\n",
        "data = '/content/drive/MyDrive/IBM_Spring24/Factor Research/mangrove_coverage.csv'\n",
        "\n",
        "agent = create_agent(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmUNoC_0T8k7"
      },
      "outputs": [],
      "source": [
        "def run_tabular_rag(query):\n",
        "  # Query the agent.\n",
        "  response = query_agent(agent=agent, query=query)\n",
        "\n",
        "  # Decode the response.\n",
        "  decoded_response = decode_response(response)\n",
        "\n",
        "  # Write the response to the Streamlit app.\n",
        "  write_response(decoded_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "dNKoqIjNZuAE",
        "outputId": "831adbc2-f40a-4450-998c-5b204b8a8d98"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "All arrays must be of the same length",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-ab76984788e7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_tabular_rag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'make a line graph for Brazil'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-277247678159>\u001b[0m in \u001b[0;36mrun_tabular_rag\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m# Write the response to the Streamlit app.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mwrite_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-3e2b5b79cc23>\u001b[0m in \u001b[0;36mwrite_response\u001b[0;34m(response_dict)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"line\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"line\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ],
      "source": [
        "run_tabular_rag('make a line graph for Brazil')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFfLl2ScaT4m"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
